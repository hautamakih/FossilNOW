{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macos/Uni/1st_year/period_3/DSProj/code/models\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as torch_nn\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from MF.model import MF\n",
    "import evaluation\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SITES_PER_PACK = 2\n",
    "NUM_SPECIES_PER_PACK = 4\n",
    "BATCH_SIZE = 25\n",
    "LR = 5e-3\n",
    "EPS = 1e-6\n",
    "N_EPOCHS = 70\n",
    "USE_REGULARIZATION = True\n",
    "PROBABILITY_OUTPUT = True\n",
    "D_HID = 10\n",
    "\n",
    "DEVICE = \"mps\"\n",
    "PATH_DIR_DATA_PROCESS = Path(\"data_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data train/val and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_data = PATH_DIR_DATA_PROCESS / \"trainval\"\n",
    "\n",
    "path_data_train = path_dir_data / \"data_train.npy\"\n",
    "path_data_val = path_dir_data / \"data_val.npy\"\n",
    "\n",
    "data_train = np.load(path_data_train, allow_pickle=True)\n",
    "data_val = np.load(path_data_val, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_encode = PATH_DIR_DATA_PROCESS / \"encoder\"\n",
    "\n",
    "path_enc_species = path_dir_encode / \"ordinal_enc_species.json\"\n",
    "path_enc_site = path_dir_encode / \"ordinal_enc_site.json\"\n",
    "\n",
    "enc_species = utils.CategoryDict.from_file(path_enc_species)\n",
    "enc_site = utils.CategoryDict.from_file(path_enc_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create train/val data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FossilNOW(Dataset):\n",
    "    def __init__(self, data: list) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]    \n",
    "    \n",
    "        occurence = torch.tensor(x['occurence'], device=DEVICE, dtype=torch.float32)\n",
    "        sites = torch.tensor(x['sites'], device=DEVICE, dtype=torch.int32)\n",
    "        species = torch.tensor(x['genera'], device=DEVICE, dtype=torch.int32)\n",
    "\n",
    "        return occurence, sites, species\n",
    "    \n",
    "dataset_train, dataset_val = FossilNOW(data_train), FossilNOW(data_val)\n",
    "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MF(\n",
    "    enc_site.size(),\n",
    "    enc_species.size(),\n",
    "    d_hid=D_HID,\n",
    "    prob_output=PROBABILITY_OUTPUT,\n",
    ")\n",
    "# mf.load_state_dict(torch.load(\"model_best_PROBABILITY_OUTPUT=False_0.1747.pt\"))\n",
    "mf = mf.to(device=torch.device(DEVICE))\n",
    "\n",
    "optimizer = AdamW(mf.parameters(), lr=LR, weight_decay=2e-5 if USE_REGULARIZATION else 0)\n",
    "criterion = torch_nn.MSELoss(reduction=\"none\")\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, 1.0, 5e-2, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(occ: torch.Tensor, pred: torch.Tensor, alpha: float = 10):\n",
    "    loss = criterion(occ, pred)\n",
    "\n",
    "    confidence = 1 + alpha * occ\n",
    "    loss = torch.mean(confidence * loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for x in tqdm(loader, total=math.ceil(len(dataset_train) / BATCH_SIZE)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        occurence, idx_sites, idx_species = x\n",
    "\n",
    "        pred = model(idx_sites, idx_species)\n",
    "        loss = calc_loss(occurence, pred)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "def val(model, loader) -> tuple:\n",
    "    preds = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        for x in tqdm(loader, total=int(math.ceil(len(dataset_val) / BATCH_SIZE))):\n",
    "            occurence, idx_sites, idx_species = x\n",
    "\n",
    "            pred = model(idx_sites, idx_species)\n",
    "            loss = calc_loss(occurence, pred)\n",
    "\n",
    "            preds.append({\n",
    "                'sites': idx_sites.detach().cpu().numpy(),\n",
    "                'species': idx_species.detach().cpu().numpy(), \n",
    "                'occurence': occurence.detach().cpu().numpy(),\n",
    "                'prediction': pred.detach().cpu().numpy()\n",
    "            })\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    loss = sum(losses)/len(losses)\n",
    "\n",
    "    return loss, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch: 00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b865a3f1c2e4547bf13deb33f542867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bf466bb1eb40f88c325555a133c1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.3306711742889534\n",
      "== Epoch: 01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f527724dcf1147b4bdf8032521f5e952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb24f94221346658844eadce1f73c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.17894929068759807\n",
      "== Epoch: 02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb14f957f2c43fd97508d56dd6a6aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c62270b8cb4a298623ac93ae716b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.15959250688263513\n",
      "== Epoch: 03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5ca41796054f13afcacf2ef09f4aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cacca0f8a524f50b736ecad5f9c5d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.1424806959999418\n",
      "== Epoch: 04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370ea3d4e06e42d9aebad9dead609e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdaa70d29234c9faffa9560ad2ce931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.12674113959797378\n",
      "== Epoch: 05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcab636f56b74fdf800d53ff51b2bdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41b07483a96474ca74b1a39704f0ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.11550664959601986\n",
      "== Epoch: 06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b25d9527aa54ab4993c6fe5395a6056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fcf8e308af4eb79169d7208ac85b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.10930152475219039\n",
      "== Epoch: 07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0572a5f42c4428a259031e5cdc5dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51aea71481ae476a9ab1348f45857d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.10447654705856321\n",
      "== Epoch: 08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aa826f18484946b6dd890b124b9eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fef8564326e48109c86a2fd6f7f3fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.10223171049819409\n",
      "== Epoch: 09\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6235473f0a444ca8a0a27082b5ec8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def3ee42c6a04bbcb47336bd901ac8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss val: 0.1000989092224576\n",
      "== Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0dd41d5d4a4d99bc80c8e2d86ca3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc16d419652499d82303d337aef9a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss_val = 10e10\n",
    "\n",
    "for n in range(N_EPOCHS):\n",
    "    print(f\"== Epoch: {n:02d}\")\n",
    "    \n",
    "    train(mf, loader_train, optimizer)\n",
    "\n",
    "    loss_val, preds_val = val(mf, loader_val)\n",
    "\n",
    "    if loss_val < best_loss_val:\n",
    "        best_loss_val = loss_val\n",
    "        torch.save(mf.state_dict(), f\"model_best_PROBABILITY_OUTPUT={PROBABILITY_OUTPUT}_{loss_val:.4f}.pt\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    print(f\"Loss val: {loss_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccb384eceb04ed79bc9f2f70813682f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>species</th>\n",
       "      <th>occurence</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site  species  occurence      pred\n",
       "0   198      116        0.0  0.003366\n",
       "1   198      117        0.0  0.117846\n",
       "2   198      118        0.0  0.051285\n",
       "3   198      119        0.0  0.020756\n",
       "4   199      116        0.0  0.008086"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_preds = []\n",
    "\n",
    "_, preds = val(mf, loader_val)\n",
    "for pred in preds:\n",
    "    for sites, species, occu, pre in zip(pred['sites'], pred['species'], pred['occurence'], pred['prediction']):\n",
    "        for i in range(NUM_SITES_PER_PACK):\n",
    "            for j in range(NUM_SPECIES_PER_PACK):\n",
    "                list_preds.append({\n",
    "                    'site': sites[i],\n",
    "                    'species': species[j],\n",
    "                    'occurence': occu[i, j],\n",
    "                    'pred': pre[i, j]\n",
    "                })\n",
    "\n",
    "df_pred = pd.DataFrame.from_records(list_preds)\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Percentile Ranking : 0.160329\n",
      "TPR : 0.022789\n"
     ]
    }
   ],
   "source": [
    "print(f\"Expected Percentile Ranking : {evaluation.calc_expected_percentile_rank(df_pred):.6f}\")\n",
    "if PROBABILITY_OUTPUT is True:\n",
    "    print(f\"TPR : {evaluation.calc_tpr(df_pred):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save model and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "\n",
    "path_dir_weights = PATH_DIR_DATA_PROCESS / f\"mf_PROBABILITY_OUTPUT={PROBABILITY_OUTPUT}/{tag}\"\n",
    "\n",
    "path_dir_weights.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sites, emb_species = mf.get_embds()\n",
    "\n",
    "path_embd_sites = path_dir_weights / \"emb_sites.npy\"\n",
    "path_embd_species = path_dir_weights / \"emb_species.npy\"\n",
    "\n",
    "np.save(path_embd_sites, emb_sites)\n",
    "np.save(path_embd_species, emb_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mf.state_dict(), path_dir_weights / \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
